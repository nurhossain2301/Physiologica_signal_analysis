{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\NONAME\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\NONAME\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\NONAME\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\NONAME\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\NONAME\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\NONAME\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import scipy.io\n",
    "from scipy.spatial.distance import pdist, squareform #scipy spatial distance\n",
    "import sklearn as sk\n",
    "import sklearn.metrics.pairwise\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, LeakyReLU\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "import time\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Reshape\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('../Dataset/EMG/DL_all_subject.mat')\n",
    "EMG_data=mat['DL_all_subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segments_and_labels(df, time_steps, step, label_name):\n",
    "\n",
    "    # Ch1, Ch2 data as features\n",
    "    N_FEATURES = 2\n",
    "    # Number of steps to advance in each iteration (for me, it should always\n",
    "    # be equal to the time_steps in order to have no overlap between segments)\n",
    "    # step = time_steps\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        xs = df['Ch1'].values[i: i + time_steps]\n",
    "        ys = df['Ch2'].values[i: i + time_steps]\n",
    "        # Retrieve the most often used label in this segment\n",
    "        label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "        segments.append([xs, ys])\n",
    "        labels.append(label)\n",
    "\n",
    "    # Bring the segments into a better shape\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    return reshaped_segments, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'label': EMG_data[:, 0], 'Ch1': EMG_data[:, 1], 'Ch2': EMG_data[:, 2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Ch1</th>\n",
       "      <th>Ch2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072198</td>\n",
       "      <td>0.202185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148703</td>\n",
       "      <td>0.227693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148703</td>\n",
       "      <td>0.304216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021195</td>\n",
       "      <td>0.227693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352716</td>\n",
       "      <td>0.278708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label       Ch1       Ch2\n",
       "0    0.0  0.072198  0.202185\n",
       "1    0.0  0.148703  0.227693\n",
       "2    0.0  0.148703  0.304216\n",
       "3    0.0  0.021195  0.227693\n",
       "4    0.0  0.352716  0.278708"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "label = df['label']\n",
    "df_v1 = df[['Ch1', 'Ch2']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_periods = 150\n",
    "step_distance = 15\n",
    "\n",
    "X, Y = create_segments_and_labels(df, Time_periods, step_distance, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(X)) < 0.8\n",
    "X_train = X[msk]\n",
    "Y_train = Y[msk]\n",
    "X_test = X[~msk]\n",
    "Y_test = Y[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "idx = np.random.permutation(len(X_train))\n",
    "X_train = X_train[idx]\n",
    "Y_train = Y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (143995, 300)\n",
      "input_shape: 300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(143995,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (Time_periods*2)\n",
    "X_train = X_train.reshape(X_train.shape[0], input_shape)\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('input_shape:', input_shape)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New y_train shape:  (143995, 6)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train.astype('float32')\n",
    "y_train = Y_train.astype('float32')\n",
    "y_train_hot = np_utils.to_categorical(y_train, 6)\n",
    "print('New y_train shape: ', y_train_hot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 150, 2)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 141, 100)          2100      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 132, 100)          100100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 44, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 35, 160)           160160    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 26, 160)           256160    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 966       \n",
      "=================================================================\n",
      "Total params: 519,486\n",
      "Trainable params: 519,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_m = Sequential()\n",
    "model_m.add(Reshape((150, 2), input_shape=(input_shape,)))\n",
    "model_m.add(Conv1D(100, 10, activation='relu', input_shape=(Time_periods, 2)))\n",
    "model_m.add(Conv1D(100, 10, activation='relu'))\n",
    "model_m.add(MaxPooling1D(3))\n",
    "model_m.add(Conv1D(160, 10, activation='relu'))\n",
    "model_m.add(Conv1D(160, 10, activation='relu'))\n",
    "model_m.add(GlobalAveragePooling1D())\n",
    "model_m.add(Dropout(0.5))\n",
    "model_m.add(Dense(6, activation='softmax'))\n",
    "print(model_m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 115196 samples, validate on 28799 samples\n",
      "Epoch 1/10\n",
      "115196/115196 [==============================] - 397s 3ms/step - loss: 0.9425 - acc: 0.6121 - val_loss: 0.6601 - val_acc: 0.7241\n",
      "Epoch 2/10\n",
      "115196/115196 [==============================] - 359s 3ms/step - loss: 0.6120 - acc: 0.7534 - val_loss: 0.4474 - val_acc: 0.8305\n",
      "Epoch 3/10\n",
      "115196/115196 [==============================] - 339s 3ms/step - loss: 0.4634 - acc: 0.8224 - val_loss: 0.3646 - val_acc: 0.8629\n",
      "Epoch 4/10\n",
      "115196/115196 [==============================] - 354s 3ms/step - loss: 0.3831 - acc: 0.8584 - val_loss: 0.3142 - val_acc: 0.8828\n",
      "Epoch 5/10\n",
      "115196/115196 [==============================] - 369s 3ms/step - loss: 0.3276 - acc: 0.8809 - val_loss: 0.2977 - val_acc: 0.8864\n",
      "Epoch 6/10\n",
      "115196/115196 [==============================] - 416s 4ms/step - loss: 0.2843 - acc: 0.8969 - val_loss: 0.2552 - val_acc: 0.9087\n",
      "Epoch 7/10\n",
      "115196/115196 [==============================] - 405s 4ms/step - loss: 0.2560 - acc: 0.9073 - val_loss: 0.2274 - val_acc: 0.9167\n",
      "Epoch 8/10\n",
      "115196/115196 [==============================] - 348s 3ms/step - loss: 0.2290 - acc: 0.9172 - val_loss: 0.2126 - val_acc: 0.9242\n",
      "Epoch 9/10\n",
      "115196/115196 [==============================] - 364s 3ms/step - loss: 0.2049 - acc: 0.9254 - val_loss: 0.2246 - val_acc: 0.9239\n",
      "Epoch 10/10\n",
      "115196/115196 [==============================] - 352s 3ms/step - loss: 0.1866 - acc: 0.9330 - val_loss: 0.2000 - val_acc: 0.9289\n"
     ]
    }
   ],
   "source": [
    "model_m.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Hyper-parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
    "history = model_m.fit(x_train,\n",
    "                      y_train_hot,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      validation_split=0.2,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 5 5 5]\n",
      "[0 0 0 ... 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "input_shape = (Time_periods*2)\n",
    "X_test = X_test.reshape(X_test.shape[0], input_shape)\n",
    "y_pred_test = model_m.predict(X_test)\n",
    "# Take the class with the highest probability from the test predictions\n",
    "max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "max_y_pred_test.shape\n",
    "print(max_y_pred_test)\n",
    "Y_test = Y_test.astype('int')\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      6029\n",
      "           1       0.94      0.95      0.94      6130\n",
      "           2       0.98      0.92      0.95      5968\n",
      "           3       0.91      0.93      0.92      5972\n",
      "           4       0.90      0.96      0.93      5962\n",
      "           5       0.95      0.87      0.91      5934\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     35995\n",
      "   macro avg       0.93      0.93      0.93     35995\n",
      "weighted avg       0.93      0.93      0.93     35995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(Y_test, max_y_pred_test)\n",
    "print(classification_report(Y_test, max_y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9314904847895541\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
